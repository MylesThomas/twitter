---
title: "Exploring Stability and Predictive Power of Scoring Statistics in the NBA"
description: |
  Comparing box score statistics and ShotQuality expectation metrics to understand the randomness of single game samples to improve prediction accuracy
author:
  - name: Myles Thomas
    url: https://twitter.com/WisconsinStats
    affiliation: ShotQuality
    affiliation_url: https://shotquality.com/
date: "`r Sys.Date()`"
output: distill::distill_article
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  message = FALSE, 
  warning = FALSE, 
  include = FALSE,
  dpi = 300, 
  tidy = 'styler'
)

options(scipen = 999)
```


```{r more setup}
# Load libraries
library(tidyverse)
library(gt)
library(tidymodels)
library(ggthemes)
library(ggtext)
library(stringi)
library(gt)
library(rmarkdown)
library(rlang)

# Files with nba team logos, colors, etc
team_info <- read.csv("C:/Users/Myles/OneDrive/Documents/GitHubThings/twitter/datasets/nba-team-logos-and-colors.csv")

headshots <- readxl::read_excel("C:/Users/Myles/OneDrive/Documents/GitHubThings/twitter/datasets/nba-player-info-headshots.xlsx", sheet = 1)

# GT functions
gt_theme_538 <- function(data,...) {
  data %>%
  opt_all_caps()  %>%
  opt_table_font(
    font = list(
      google_font("Chivo"),
      default_fonts()
    )
  ) %>%
    tab_style(
      style = cell_borders(
        sides = "bottom", color = "transparent", weight = px(2)
      ),
      locations = cells_body(
        columns = everything(),
        # This is a relatively sneaky way of changing the bottom border
        # Regardless of data size
        rows = nrow(data$`_data`)
      )
    )  %>% 
  tab_options(
    column_labels.background.color = "white",
    table.border.top.width = px(3),
    table.border.top.color = "transparent",
    table.border.bottom.color = "transparent",
    table.border.bottom.width = px(3),
    column_labels.border.top.width = px(3),
    column_labels.border.top.color = "transparent",
    column_labels.border.bottom.width = px(3),
    column_labels.border.bottom.color = "black",
    data_row.padding = px(3),
    source_notes.font.size = 12,
    table.font.size = 16,
    heading.align = "left",
    ...
  ) 
}

gt_theme_espn <- function(data, ...){
  data %>% 
    opt_all_caps()  %>%
    opt_table_font(
      font = list(
        google_font("Lato"),
        default_fonts()
      )
    )  %>% 
    opt_row_striping() %>% 
    tab_options(
      row.striping.background_color = "#fafafa",
      table_body.hlines.color = "#f6f7f7",
      source_notes.font.size = 12,
      table.font.size = 16,
      table.width = px(925),
      heading.align = "left",
      heading.title.font.size = 24,
      table.border.top.color = "transparent",
      table.border.top.width = px(3),
      data_row.padding = px(7),
      ...
    ) 
}

# Set a theme
theme_set(theme_bw() +
            theme(plot.title = element_text(face = "bold", size = 28/.pt, hjust = 0),
                  plot.subtitle = element_text(face = "italic", size = 24/.pt),
                  strip.background = element_rect(color = "black", fill = "#C0C0C0", size = 3.5, linetype = "blank"),
                  strip.text = element_text(face = "bold", size = 24/.pt),
                  panel.grid.minor.x = element_blank(),
                  panel.grid.minor.y = element_blank(),
                  panel.border = element_blank(),
                  axis.ticks = element_blank(),
                  axis.text = element_text(size = 24/.pt),
                  axis.title = element_text(face = "bold", size = 26/.pt),
                  plot.caption = element_text(face = "italic", size = 20/.pt),
                  legend.title = element_text(size = 24/.pt),
                  legend.text = element_text(size = 20/.pt),
                  legend.key.size = unit(0.75, "lines")))
```


```{r calc shots taken}
# load player by player data
df <- readr::read_csv("../data/player_data.csv")

# add up number of 2pt / 3pt and FT's taken
t <- df %>%
  select(Players, `Shot Attempts`, `Free Throw Attempts`) %>%
  summarise(shots = sum(`Shot Attempts`),
            fts = sum(`Free Throw Attempts`))

t[1,1] + t[1,2]
```


As we approach the new year, in the 2021-2022 NBA Season there have been over 107,587 shots taken. In a make or miss league, scoring performance has a huge influence on game outcomes and also on advanced metrics like points per possession (PPP) and true shooting percentage (TS%). One of the reasons that many highly regarded power ranking systems had the 2020 New York Knicks rated lower was due to their "luckiness" with opponent 3-point percentage. Are certain scoring statistics a reflection of a team's underlying talent/skill, or are they simply random noise that will fluctuate game-by-game and cannot predict future performance? If we find that certain metrics are stable for teams and/or players throughout a season, we can incorporate scoring regression to make better predictions out of sample.




```{r peaking at data, include=FALSE, layout="l-body-outset", echo=FALSE}

# Letâ€™s start by first reading in game summary data by team from 2021 from the ShotQuality database.

nba_team_data <-
  readr::read_csv("../data/team_data.csv") %>%
  select(-c(X1, ends_with("diff"))) %>%
  arrange(Logos, games_ids)

nba_team_data %>%
  rmarkdown::paged_table()
```


# Exploring stability of box score statistics

Single game performances tend to be noisy, especially when looking at individual statistics. Using the mean values for each box score statistic for each individual game, we will bucket each team and box score statistic into 5 game rolling windows and find the correlation across teams during this season. 

```{r}
# grab the columns I will be working with (for the most part)

df <- nba_team_data %>%
  select(-dplyr::ends_with("Difference")) %>%
  select(-c(`Shot Attempts`:`Free Throw Attempts`)) %>% # remove the ones that we cannot compare anything to
  select(-dplyr::starts_with("Post")) %>%
  select(-c(Opponent:`Point Differential`))

df
```

```{r melt and get bin of means for each variable}
num <- 5

binned_means <- df %>% 
  reshape2::melt(id.vars = c("Logos", "games_ids")) %>% # group by team/statistical measures
  dplyr::group_by(Logos, variable) %>% 
  dplyr::mutate(game_number = dplyr::row_number()) %>% # mutate in the running game number for that team/measure
  dplyr::ungroup() %>%
  dplyr::mutate(game_cut = cut(game_number, breaks = seq(0, 50, by = num))) %>%
  dplyr::select(-c(games_ids)) %>% # get rid of these now that we have game_cut (game_number in to check things)
  tidyr::complete(nesting(Logos, game_cut, variable), fill = list(n = 0)) %>% 
  dplyr::arrange(Logos, game_cut, variable) %>%  # fill/arrange/group_by 
  dplyr::group_by(Logos, game_cut, variable) %>% # Team, Grouping(game_cut), Variable
  dplyr::summarise(bin_mean = mean(value),       # get mean of each variable for each combo of Team/game_cut
                   .groups = "drop") %>%
    dplyr::ungroup()

binned_means
```

```{r lag over each combination of team and bin and variable}
# lag over each combination of team, bin, variable
lagged <- binned_means %>%
  tidyr::complete(nesting(Logos, game_cut, variable), fill = list(n = 0)) %>% # Set up Complete/Arrange on Team, Cut, Var
  dplyr::arrange(Logos, game_cut, variable) %>%
  dplyr::group_by(Logos, variable) %>% # take out categorical bin (game_cut)
  dplyr::mutate(prev_bin_mean = dplyr::lag(bin_mean, default = NA)) %>% # lag, so each Team/Var is lagged by prev. bin
  dplyr::ungroup() %>%
  dplyr::mutate(weight = sqrt(bin_mean^2 + prev_bin_mean^2)) # get weights for weighted regression

lagged

# remove any rows that we cannot calculate a correlation for
lagged2 <- lagged %>%
  dplyr::filter(!is.na(weight))

lagged2
```


```{r fit models}
# WITH weighted regression
results <- lagged2 %>%
  tidyr::nest(data = c(Logos, game_cut, bin_mean, prev_bin_mean, weight)) %>% # nest so we can map over 24 vars
  # using previous bin to predict the future bin
  dplyr::mutate(fit = map(data, ~ lm(bin_mean ~ prev_bin_mean, weights = weight, data = .)),
                # this 'glanced' function returns a one-row data frame of model information
                results = map(fit, broom::glance)) %>%
  # this 'unnest' takes the nested results and turns them into columns
  tidyr::unnest(cols = c(results)) 
  
# WITHOUT weighted regression
results_unweighted <- lagged2 %>%
  tidyr::nest(data = c(Logos, game_cut, bin_mean, prev_bin_mean, weight)) %>% 
  dplyr::mutate(fit = map(data, ~ lm(bin_mean ~ prev_bin_mean, data = .)),
                results = map(fit, broom::glance)) %>%
  tidyr::unnest(cols = c(results)) 

# looking at weighted regression of vars I am interested in
results %>%
  select(variable, r.squared) %>%
  arrange(desc(r.squared))
```


```{r stability of box score metrics, include=TRUE, echo=FALSE, layout="l-body", fig.height=3.5}
results %>%
  select(variable, r.squared) %>%
  arrange(desc(r.squared)) %>%
  slice(6:10) %>%
  mutate(variable = reorder(variable, r.squared)) %>%
  ggplot(aes(r.squared, variable)) +
  geom_col(show.legend = F, fill = "blue4", width = 0.5) +
  geom_text(aes(label = round(r.squared, 4)),
            hjust = 1, size = 2.5, color = "white", fontface = "bold") +
  scale_x_continuous(expand = c(0, 0)) +
  scale_fill_brewer(palette = "Set1") +
  theme(panel.grid.major.y = element_blank(),
        strip.background = element_rect(color = "black", fill = "#C0C0C0", size = 1.5, linetype = "blank"),
        strip.text = element_text(face = "bold", size = 20/.pt),
        legend.position = "top") +
  labs(x = expression(bold("5 Game Bucket Correlation:"~R^2)),
       y = NULL,
       fill = NULL,
       title = "Stability of box score statistics in the NBA",
       subtitle = "Correlation of team scoring statistics across five game windows",
       caption = "Chart: @Shot_Quality | 2021-2022 Season")
```

These results are fairly intuitive. While the number of points scored and the free throw is less fluky, shooting percentages all over the court fluctuate wildly from game to game. It also makes sense that the free throw has better stability than the live shooting percentages considering a shot taken at a deal ball with no defense will rely on *skill* rather than luck.

# Exploring stability of ShotQuality metrics

ShotQuality expectation variables were created to derive process-based insights on the quality of possessions. This takes into account the individual player's shot making ability when computing, so these metrics should have better stability and robustness to the noise of a lucky game, right? Let's repeat the analysis using the SQ expectations.

```{r sq is much improved, include=TRUE, echo=FALSE, layout="l-body", fig.height=3.5}
results %>%
  select(variable, r.squared) %>%
  arrange(desc(r.squared)) %>%
  slice(1:5) %>%
  mutate(variable = reorder(variable, r.squared)) %>%
  ggplot(aes(r.squared, variable)) +
  geom_col(show.legend = F, fill = "orange1", width = 0.5) +
  geom_text(aes(label = round(r.squared, 4)),
            hjust = 1, size = 2.5, color = "white", fontface = "bold") +
  scale_x_continuous(expand = c(0, 0)) +
  scale_fill_brewer(palette = "Set1") +
  theme(panel.grid.major.y = element_blank(),
        strip.background = element_rect(color = "black", fill = "#C0C0C0", size = 1.5, linetype = "blank"),
        strip.text = element_text(face = "bold", size = 20/.pt),
        legend.position = "top") +
  labs(x = expression(bold("5 Game Bucket Correlation:"~R^2)),
       y = NULL,
       fill = NULL,
       title = "Stability of ShotQuality metrics in the NBA",
       subtitle = "Correlation of team SQ statistics across five game windows",
       caption = "Chart: Data: @Shot_Quality | 2021-2022 Season")

```

Wow! The game to game correlation between the ShotQuality metrics is far superior to that of ordinary box score statistics. Putting the correlations on the same axis should further hammer this point home.

```{r sq vs box score, include=TRUE, echo=FALSE, layout="l-body", fig.height=5}
results %>%
  select(variable, r.squared) %>%
  arrange(desc(r.squared)) %>%
  mutate(variable = reorder(variable, r.squared),
         grp = c(rep("ShotQuality", 5), rep("Box Score", 5)),
         grp = factor(grp)) %>%
  ggplot(aes(r.squared, variable, fill = grp)) +
  geom_col(show.legend = F, width = 0.5) +
  geom_text(aes(label = round(r.squared, 4)),
            hjust = 1, size = 2.5, color = "white", fontface = "bold") +
  scale_fill_manual(values = c("blue4", "orange1")) +
  scale_x_continuous(expand = c(0, 0)) +
  theme(panel.grid.major.y = element_blank(),
        strip.background = element_rect(color = "black", fill = "#C0C0C0", size = 1.5, linetype = "blank"),
        strip.text = element_text(face = "bold", size = 20/.pt),
        legend.position = "top") +
  labs(x = expression(bold("5 Game Bucket Correlation:"~R^2)),
       y = NULL,
       fill = NULL,
       title = "Stability of ShotQuality metrics vs box score statistics in the NBA",
       subtitle = "Correlation of across five game windows",
       caption = "Chart: Data: @Shot_Quality | 2021-2022 Season")

```

We now know that generally, box score statistics are extremely fluky and unstable metrics for teams, especially for shooting percentages. Given this information, how can we take this into account for prediction? If we are going to predict future game outcomes, it might be smart to create a weighted 'game grade' model measured by its `RSQ` to future points scored (ie, out of sample point differential).

```{r}
# remove dataframes from the environment
rm(binned_means, df, headshots, lagged, lagged2, nba_team_data, results, results_unweighted, t, team_info)
```


# Descriptive vs Predictive

In this analysis, a statisticâ€™s ability to describe the final score of a game is measured by its correlation to the same gameâ€™s point differential. A game gradeâ€™s ability to predict future performance is measured by its RSQ to future point differential (aka out of sample point differential).

The out of sample RSQ is measured across three rolling windows: 1 game, 4 games, and 8 games. The windows are equally sized (not rolling, expanding, or dynamically moving windows) and constrained to games from this season. For example, a team approaching game number 5 has 4 preceding games (1, 2, 3 and 4) that are used to make a prediction about the teamâ€™s next 4 games (games 5, 6, 7, and 8). Those games (5, 6, 7, and 8) are used to predict the next 4 games (9, 10, 11 and 12), and so on:

```{r}
# read in dataset with home team data
team_data <- readr::read_csv("../data/team_data.csv")

team_data
```


```{r}
# Explanatory power:
# Correlation with Points Differential.
numerics <- team_data %>%
  select(is.numeric) %>%
  select(-c(X1, games_ids)) %>%
  select(`Point Differential`, `Points Expected`:`Points Allowed`)
  #select(`Points Scored`, `Points Expected`, `Points Difference`:`Point Differential`)

in_sample <- cor(numerics) %>% 
  as.data.frame() %>% 
  select(`Point Differential`) %>% 
  mutate(rsq = (`Point Differential`)*(`Point Differential`)) %>% 
  arrange(desc(`rsq`))

in_sample


in_sample$var <- rownames(in_sample)

s1 <- in_sample %>%
  t() %>%
  as_tibble() %>%
  slice(2)

s1$col <- c("Correlation to Same Game PD")

s1 <- s1 %>%
  select(col, `Point Differential`,
         `Points Scored`, `Points Expected`,
         `3PT FG%`, `3PT FG% Expected`,
         `Midrange FG%`, `Midrange FG% Expected`,
         `Free Throw %`, `Free Throw % Expected`,
         `Post Up FG%`, `Post Up FG% Expected`)

s1

# "Correlation to Same Game PD","OoS RSQ to PD (1 Game Window)","OoS RSQ to PD (4 Game Window)","OoS RSQ to PD (8 Game Window)"
```


```{r setting up function}
num <- 4

# view initial data
team_data

# bin data based on team, game number
binned_means <- team_data %>% 
  select(Logos, games_ids, `Point Differential`, `Points Scored`) %>% # SELECT VARIABLE HERE.
  dplyr::group_by(Logos) %>% 
  dplyr::mutate(game_number = dplyr::row_number()) %>% # mutate in the running game number for that team/measure
  dplyr::ungroup() %>%
  dplyr::mutate(game_cut = cut(game_number, breaks = seq(0, 50, by = num))) %>%
  dplyr::group_by(Logos, game_cut) %>%
  summarise("Point Differential" = mean(`Point Differential`),
            Current = mean(`Points Scored`),
            .groups = "drop")

binned_means

# lag over each combination of team, bin, variable
lagged <- binned_means %>%
  dplyr::select(Logos, game_cut, `Point Differential`, Current) %>% # now that we have bins, do not need game id or number
  tidyr::complete(nesting(Logos, game_cut), fill = list(n = 0)) %>% # Set up Complete/Arrange on Team & Cut
  dplyr::arrange(Logos, game_cut) %>%
  dplyr::group_by(Logos) %>% # take out game_cut
  dplyr::mutate(`Prev` = dplyr::lag(`Current`, default = NA)) %>% # lag
  dplyr::ungroup() %>%
  dplyr::mutate(Weight = sqrt(`Current`^2 + `Prev`^2)) # get weights for weighted regression

lagged

# remove any rows that we cannot calculate a correlation for
lagged2 <- lagged %>%
  dplyr::filter(!is.na(Weight))

lagged2

# get results with UN-WEIGHTED linear regression
results <- lagged2 %>%
  tidyr::nest(data = everything()) %>% # nest everything to get 1 score for RSQ
  # using previous bin to predict the Point Differential
  dplyr::mutate(fit = map(data, ~ lm(`Point Differential` ~ Prev, data = .)),
                results = map(fit, broom::glance)) %>%
  tidyr::hoist(results, r_squared = "r.squared")

ret <- dplyr::bind_cols(results, yardstick::rsq(lagged2, truth = lagged2$`Point Differential`, estimate = lagged2$Prev)) %>%
  mutate(var_name = "Points Scored") %>%
  select(var_name, r_squared, .estimate)

ret
```


```{r}
predict_point_differential <- function(data, predictor, bin_size = 1) {
  # bin data based on team, game number
  bins_fun <- data %>% 
    select(Logos, games_ids, `Point Differential`, predictor) %>% 
    dplyr::group_by(Logos) %>% 
    dplyr::mutate(game_number = dplyr::row_number()) %>%
    dplyr::ungroup() %>%
    dplyr::mutate(game_cut = cut(game_number, breaks = seq(0, 100, by = bin_size))) %>%
    dplyr::group_by(Logos, game_cut) %>%
    summarise("Point Differential" = mean(`Point Differential`),
              Current = mean(!!sym(predictor)),
              .groups = "drop")

  lag <- bins_fun %>%
    dplyr::select(Logos, game_cut, `Point Differential`, Current) %>% # now that we have bins, do not need game id or number
    tidyr::complete(nesting(Logos, game_cut), fill = list(n = 0)) %>% # Set up Complete/Arrange on Team & Cut
    dplyr::arrange(Logos, game_cut) %>%
    dplyr::group_by(Logos) %>% # take out game_cut
    dplyr::mutate(`Prev` = dplyr::lag(`Current`, default = NA)) %>% # lag
    dplyr::ungroup() %>%
    dplyr::mutate(Weight = sqrt(`Current`^2 + `Prev`^2)) # get weights for weighted regression

  lag2 <- lag %>%
    dplyr::filter(!is.na(Weight))

  res <- lag2 %>%
    tidyr::nest(data = everything()) %>% # nest everything to get 1 score for RSQ
    # using previous bin to predict the Point Differential
    dplyr::mutate(fit = map(data, ~ lm(`Point Differential` ~ Prev, data = .)),
                  results = map(fit, broom::glance)) %>%
    tidyr::hoist(results, r_squared = "r.squared")
  
  ret <- dplyr::bind_cols(res, yardstick::rsq(lag2, truth = lag2$`Point Differential`, estimate = lag2$Prev)) %>%
    mutate(var_name = predictor) %>%
    select(var_name, r_squared, .estimate)
  
  numeric_form <- as.numeric(ret[1, 3])
  
  return(numeric_form)
  
}

predict_point_differential(team_data, predictor = "Points Scored", bin_size = 1)
predict_point_differential(team_data, predictor = "Points Scored", bin_size = 4)
predict_point_differential(team_data, predictor = "Points Scored", bin_size = 8)
```


```{r}
# Putting together data for GT Table
tib <- dplyr::tibble(
  cols = c("Correlation to Same Game PD",
           "OoS RSQ to PD (1 Game Window)",
           "OoS RSQ to PD (4 Game Window)",
           "OoS RSQ to PD (8 Game Window)"),
  
  "point_diff" = c(s1$`Point Differential`,
                   predict_point_differential(team_data, predictor = "Point Differential", bin_size = 1),
                   predict_point_differential(team_data, predictor = "Point Differential", bin_size = 4),
                   predict_point_differential(team_data, predictor = "Point Differential", bin_size = 8)),
  
  "pts" = c(s1$`Points Scored`,
            predict_point_differential(team_data, predictor = "Points Scored", bin_size = 1),
            predict_point_differential(team_data, predictor = "Points Scored", bin_size = 4),
            predict_point_differential(team_data, predictor = "Points Scored", bin_size = 8)),
  
  "pred_pts" = c(s1$`Points Expected`,
                 predict_point_differential(team_data, predictor = "Points Expected", bin_size = 1),
                 predict_point_differential(team_data, predictor = "Points Expected", bin_size = 4),
                 predict_point_differential(team_data, predictor = "Points Expected", bin_size = 8)),
  
  "threes" = c(s1$`3PT FG%`,
               predict_point_differential(team_data, predictor = "3PT FG%", bin_size = 1),
               predict_point_differential(team_data, predictor = "3PT FG%", bin_size = 4),
               predict_point_differential(team_data, predictor = "3PT FG%", bin_size = 8)),
  
  "pred_threes" = c(s1$`3PT FG% Expected`,
                    predict_point_differential(team_data, predictor = "3PT FG% Expected", bin_size = 1),
                    predict_point_differential(team_data, predictor = "3PT FG% Expected", bin_size = 4),
                    predict_point_differential(team_data, predictor = "3PT FG% Expected", bin_size = 8)),
  
  "mid" = c(s1$`Midrange FG%`,
            predict_point_differential(team_data, predictor = "Midrange FG%", bin_size = 1),
            predict_point_differential(team_data, predictor = "Midrange FG%", bin_size = 4),
            predict_point_differential(team_data, predictor = "Midrange FG%", bin_size = 8)),
  
  "pred_mid" = c(s1$`Midrange FG% Expected`,
                 predict_point_differential(team_data, predictor = "Midrange FG% Expected", bin_size = 1),
                 predict_point_differential(team_data, predictor = "Midrange FG% Expected", bin_size = 4),
                 predict_point_differential(team_data, predictor = "Midrange FG% Expected", bin_size = 8)),
  
  "ft" = c(s1$`Free Throw %`,
           predict_point_differential(team_data, predictor = "Free Throw %", bin_size = 1),
           predict_point_differential(team_data, predictor = "Free Throw %", bin_size = 4),
           predict_point_differential(team_data, predictor = "Free Throw %", bin_size = 8)),
  
  "pred_ft" = c(s1$`Free Throw % Expected`,
                predict_point_differential(team_data, predictor = "Free Throw % Expected", bin_size = 1),
                predict_point_differential(team_data, predictor = "Free Throw % Expected", bin_size = 4),
                predict_point_differential(team_data, predictor = "Free Throw % Expected", bin_size = 8))#,
  
#  "post" = c(s1$`Post Up FG%`,
#             predict_point_differential(team_data, predictor = "Post Up FG%", bin_size = 1),
#             predict_point_differential(team_data, predictor = "Post Up FG%", bin_size = 4),
#             predict_point_differential(team_data, predictor = "Post Up FG%", bin_size = 8)),
#  
#  "pred_post" = c(s1$`Post Up FG% Expected`,
#             predict_point_differential(team_data, predictor = "Post Up FG% Expected", bin_size = 1),
#             predict_point_differential(team_data, predictor = "Post Up FG% Expected", bin_size = 4),
#             predict_point_differential(team_data, predictor = "Post Up FG% Expected", bin_size = 8))
)


tib
```

```{r}
# remove data not needed
rm(binned_means, team_data, in_sample, lagged, lagged2, numerics, results, ret, s1, num)
```



```{r gt table, include=TRUE, echo=FALSE, layout="l-page", fig.height=4.5}
# make GT Table
tib %>%
  mutate_at(vars(point_diff:pred_ft), .funs = as.numeric) %>%
  mutate_if(is.numeric, .funs = function(x) {round(x, 3)}) %>%
  gt() %>%
  cols_label(
    cols = "",
    point_diff = "",
    pts = "Observed",
    pred_pts = "SQ",
    threes = "Observed",
    pred_threes = "SQ",
    mid = "Observed",
    pred_mid = "SQ",
    ft = "Observed",
    pred_ft = "SQ"
    ) %>%
  tab_source_note(
    source_note = md("Chart: Data: @Shot_Quality | 2021-2022 Season")
  ) %>%
  tab_header(title = md("****"),
             subtitle = md(expression(""))) %>%
  gt_theme_espn() %>%
  tab_spanner(label = "Points", columns = c(pts:pred_pts)) %>%
  tab_spanner(label = "3PT %", columns = c(threes:pred_threes)) %>%
  tab_spanner(label = "Midrange %", columns = c(mid:pred_mid)) %>%
  tab_spanner(label = "FT %", columns = c(ft:pred_ft)) %>%
  tab_spanner(label = "Point Differential", columns = c(point_diff)) %>%
    tab_options(
      column_labels.background.color = "white",
      column_labels.font.weight = "bold",
      table.border.top.width = px(3),
      table.border.top.color = "transparent",
      table.border.bottom.color = "transparent",
      table.border.bottom.width = px(3),
      column_labels.border.top.width = px(3),
      column_labels.border.top.color = "transparent",
      column_labels.border.bottom.width = px(3),
      column_labels.border.bottom.color = "black",
      data_row.padding = px(3),
      source_notes.font.size = 12,
      table.font.size = 16,
      heading.align = "center"
    ) %>%
    opt_table_font(
      font = list(
        default_fonts()
      )
    )

```


In general, these metrics by themselves (game grades, weighting metrics and more are a topic of discussion for another time) are not able to predict out of sample very well, and are not better than the point differential. It is intuitive that for each observed box score metric, it is better at describing the same game, meanwhile the ShotQuality metrics are much more accurate at predicting future games. This holds true in every case of this analysis besides one instance of predicted free throw percentage, which is something to investigate in the future.

# Wrapping up

```{r}
# The main objective of this post was to observe the stability of scoring metrics by exploring their ability to predict future performance out of sample. The predictive power of these metrics on the point differential of games was further explored to reinforce the point: ShotQuality metrics account for game to game randomness much better than box score statistics. 

```


The main objective of this post was to look at which scoring metrics we can expect to perform similarly from night to night, and which ones are ultimately random. Understanding which metrics random (and filtering them out from the 'game score') and which are stable allows us to better rank the performance of teams on a given night.

We also looked at how well each of these metrics could predict the point differential of a future game, which is where the ShotQuality metrics outperformed the regular box score statistics. This goes to show that ShotQuality metrics account for game to game randomness much better than box score statistics and should be used to assess team performance going forward. In the future, we can investigate how ShotQuality metrics can be used to predict the outcomes of future games.


